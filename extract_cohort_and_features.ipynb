{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CRRT Mortality Prediction\n",
    "## Extraction of Patient Cohort and Feature Vectors\n",
    "### Christopher V. Cosgriff, David Sasson, Colby Wilkinson, Kanhua Yin\n",
    "\n",
    "The goal of this notebook is to form a preliminary cohort, and to extract the vital and lab features for our cohort."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import psycopg2\n",
    "\n",
    "# postgres envrionment setup; specific to me\n",
    "sqluser = 'cosgriffc'\n",
    "dbname = 'mimic'\n",
    "schema_name = 'mimiciii'\n",
    "host = 'localhost'\n",
    "\n",
    "query_schema = 'SET search_path TO ' + schema_name + ';'\n",
    "\n",
    "# connect to the database\n",
    "con = psycopg2.connect(dbname = dbname, user = sqluser, host = host)\n",
    "\n",
    "# plotting stuffs\n",
    "# \"Tableau 20\" colors as RGB.   \n",
    "tableau20 = [(31, 119, 180), (174, 199, 232), (255, 127, 14), (255, 187, 120),    \n",
    "             (44, 160, 44), (152, 223, 138), (214, 39, 40), (255, 152, 150),    \n",
    "             (148, 103, 189), (197, 176, 213), (140, 86, 75), (196, 156, 148),    \n",
    "             (227, 119, 194), (247, 182, 210), (127, 127, 127), (199, 199, 199),    \n",
    "             (188, 189, 34), (219, 219, 141), (23, 190, 207), (158, 218, 229)]  \n",
    "  \n",
    "# Scale the RGB values to the [0, 1] range, which is the format matplotlib accepts.    \n",
    "for i in range(len(tableau20)):    \n",
    "    r, g, b = tableau20[i]    \n",
    "    tableau20[i] = (r / 255., g / 255., b / 255.)\n",
    "\n",
    "marker = ['v','o','d','^','s','>','+']\n",
    "ls = ['-','-','-','-','-','s','--','--']\n",
    "\n",
    "# configure jupyter for using matplotlib on rMBP\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load base cohort \n",
    "\n",
    "Before we can run queries we need to generate the requisite materialized views. They are:\n",
    "\n",
    "1. ICU stay detail (`icustay_detail`)\n",
    "2. Vitals only CE pull (`vitals`)\n",
    "3. Labs only LE pull (`labs`)\n",
    "4. OASIS (`oasis`)\n",
    "5. OASIS dependencies: `uofirsday`, `vitalsfirstday`, `gcsfirstday`, `ventfirstday`\n",
    "6. Elixhauser score `elixhauser-ahrq-v37-no-drg-all-icd` and `elixhauser_ahrq_no_drg_all_icd_score`\n",
    "7. CRRT Durations `crrt-durations`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>icustay_id</th>\n",
       "      <th>admission_age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>intime</th>\n",
       "      <th>outtime</th>\n",
       "      <th>los_icu</th>\n",
       "      <th>icustay_seq</th>\n",
       "      <th>elixhauser_vanwalraven</th>\n",
       "      <th>oasis</th>\n",
       "      <th>exclude_los</th>\n",
       "      <th>exclude_age</th>\n",
       "      <th>ninety_expire_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100053</td>\n",
       "      <td>217069</td>\n",
       "      <td>56.6149</td>\n",
       "      <td>M</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2124-07-14 03:20:29</td>\n",
       "      <td>2124-07-19 01:54:09</td>\n",
       "      <td>4.9400</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>48</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100095</td>\n",
       "      <td>220320</td>\n",
       "      <td>84.2335</td>\n",
       "      <td>M</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>2108-09-28 20:01:23</td>\n",
       "      <td>2108-10-05 10:46:47</td>\n",
       "      <td>6.6149</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100098</td>\n",
       "      <td>216749</td>\n",
       "      <td>71.5343</td>\n",
       "      <td>F</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2108-04-04 15:26:39</td>\n",
       "      <td>2108-05-08 14:47:19</td>\n",
       "      <td>33.9727</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100108</td>\n",
       "      <td>273316</td>\n",
       "      <td>60.0889</td>\n",
       "      <td>M</td>\n",
       "      <td>UNKNOWN/NOT SPECIFIED</td>\n",
       "      <td>2143-04-29 23:28:39</td>\n",
       "      <td>2143-05-12 18:19:27</td>\n",
       "      <td>12.7853</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100364</td>\n",
       "      <td>285421</td>\n",
       "      <td>85.7991</td>\n",
       "      <td>M</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>2124-02-03 11:03:35</td>\n",
       "      <td>2124-03-08 14:52:28</td>\n",
       "      <td>34.1589</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hadm_id  icustay_id  admission_age gender              ethnicity  \\\n",
       "0   100053      217069        56.6149      M                  WHITE   \n",
       "1   100095      220320        84.2335      M  UNKNOWN/NOT SPECIFIED   \n",
       "2   100098      216749        71.5343      F                  WHITE   \n",
       "3   100108      273316        60.0889      M  UNKNOWN/NOT SPECIFIED   \n",
       "4   100364      285421        85.7991      M                  WHITE   \n",
       "\n",
       "               intime             outtime  los_icu  icustay_seq  \\\n",
       "0 2124-07-14 03:20:29 2124-07-19 01:54:09   4.9400            1   \n",
       "1 2108-09-28 20:01:23 2108-10-05 10:46:47   6.6149            1   \n",
       "2 2108-04-04 15:26:39 2108-05-08 14:47:19  33.9727            1   \n",
       "3 2143-04-29 23:28:39 2143-05-12 18:19:27  12.7853            1   \n",
       "4 2124-02-03 11:03:35 2124-03-08 14:52:28  34.1589            1   \n",
       "\n",
       "   elixhauser_vanwalraven  oasis  exclude_los  exclude_age  ninety_expire_flag  \n",
       "0                      24     48            0            0                   1  \n",
       "1                      17     28            0            0                   1  \n",
       "2                      17     33            0            0                   1  \n",
       "3                       6     49            0            0                   1  \n",
       "4                      23     47            0            0                   0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = query_schema + '''\n",
    "WITH icu_death AS\n",
    "(\n",
    "SELECT ie.icustay_id\n",
    "    , CASE\n",
    "        WHEN adm.deathtime BETWEEN ie.intime and ie.outtime\n",
    "            THEN 1\n",
    "        -- sometimes there are typographical errors in the death date, so check before intime\n",
    "        WHEN adm.deathtime <= ie.intime\n",
    "            THEN 1\n",
    "        WHEN adm.dischtime <= ie.outtime\n",
    "            AND adm.discharge_location = 'DEAD/EXPIRED'\n",
    "            THEN 1\n",
    "        ELSE 0\n",
    "        END AS icustay_expire_flag\n",
    "    , CASE\n",
    "        WHEN adm.deathtime <= (adm.dischtime + interval '90' day) THEN 1\n",
    "        ELSE 0\n",
    "        END AS ninety_expire_flag\n",
    "FROM icustays ie\n",
    "INNER JOIN admissions adm\n",
    "ON ie.hadm_id = adm.hadm_id\n",
    "),\n",
    "oasis AS\n",
    "(\n",
    "    SELECT icustay_id, oasis\n",
    "    FROM oasis\n",
    "),\n",
    "elixhauser AS\n",
    "(\n",
    "    SELECT hadm_id, elixhauser_vanwalraven FROM elixhauser_ahrq_score\n",
    ")\n",
    ", crrt AS\n",
    "(\n",
    "    SELECT i.hadm_id, SUM(c.duration_hours) as crrt_duration \n",
    "    FROM crrtdurations c\n",
    "    INNER JOIN icustays i\n",
    "    ON c.icustay_id = i.icustay_id\n",
    "    GROUP BY i.hadm_id\n",
    ")\n",
    "\n",
    "SELECT id.hadm_id, id.icustay_id, id.admission_age, id.gender, id.ethnicity, \n",
    "       id.intime, id.outtime, id.los_icu, id.icustay_seq, elix.elixhauser_vanwalraven, oa.oasis\n",
    "       , CASE WHEN id.los_icu < 0.167 THEN 1\n",
    "       ELSE 0\n",
    "       END AS exclude_los\n",
    "       , CASE WHEN id.admission_age < 16 THEN 1\n",
    "       ELSE 0\n",
    "       END AS exclude_age\n",
    "       , idth.ninety_expire_flag\n",
    "FROM icustay_detail id\n",
    "INNER JOIN icu_death idth\n",
    "ON id.icustay_id = idth.icustay_id\n",
    "INNER JOIN oasis oa\n",
    "ON id.icustay_id = oa.icustay_id\n",
    "INNER JOIN elixhauser elix\n",
    "ON id.hadm_id = elix.hadm_id\n",
    "INNER JOIN crrt\n",
    "ON id.hadm_id = crrt.hadm_id;\n",
    "'''\n",
    "    \n",
    "icu_base = pd.read_sql_query(query, con)\n",
    "icu_base.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Apply Exclusion Criteria\n",
    "\n",
    "In the previous pull I added flages for exclusion. They are:\n",
    "1. Age <16 (subject level)\n",
    "2. Length of stay in the ICU <4h (icustay level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First just drop any patient with an \n",
    "icu_cohort = icu_base[icu_base.exclude_age == 0]\n",
    "\n",
    "# Exclude hadm_id for los_exclude or died during first ICU stay\n",
    "exclude_hadm_ids = icu_cohort.hadm_id[(icu_cohort.icustay_seq >= 3) | (np.isnan(icu_cohort.los_icu))]\n",
    "\n",
    "# Drop variables no longer needed\n",
    "icu_cohort = icu_cohort.drop(['exclude_age', 'exclude_los'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hadm_id</th>\n",
       "      <td>1301.0</td>\n",
       "      <td>148959.273636</td>\n",
       "      <td>29192.003474</td>\n",
       "      <td>100053.0000</td>\n",
       "      <td>123404.0000</td>\n",
       "      <td>148860.0000</td>\n",
       "      <td>174824.0000</td>\n",
       "      <td>199919.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icustay_id</th>\n",
       "      <td>1301.0</td>\n",
       "      <td>249784.129900</td>\n",
       "      <td>28869.475428</td>\n",
       "      <td>200065.0000</td>\n",
       "      <td>224945.0000</td>\n",
       "      <td>250300.0000</td>\n",
       "      <td>274326.0000</td>\n",
       "      <td>299994.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>admission_age</th>\n",
       "      <td>1301.0</td>\n",
       "      <td>63.889437</td>\n",
       "      <td>27.018418</td>\n",
       "      <td>20.2686</td>\n",
       "      <td>51.9982</td>\n",
       "      <td>62.4700</td>\n",
       "      <td>73.3998</td>\n",
       "      <td>302.2868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>los_icu</th>\n",
       "      <td>1301.0</td>\n",
       "      <td>13.518671</td>\n",
       "      <td>14.276263</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>3.9319</td>\n",
       "      <td>9.0294</td>\n",
       "      <td>17.8257</td>\n",
       "      <td>153.9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icustay_seq</th>\n",
       "      <td>1301.0</td>\n",
       "      <td>1.280553</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>6.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elixhauser_vanwalraven</th>\n",
       "      <td>1301.0</td>\n",
       "      <td>14.716372</td>\n",
       "      <td>7.811941</td>\n",
       "      <td>-7.0000</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>15.0000</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>40.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oasis</th>\n",
       "      <td>1301.0</td>\n",
       "      <td>37.843966</td>\n",
       "      <td>9.912514</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>38.0000</td>\n",
       "      <td>45.0000</td>\n",
       "      <td>66.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ninety_expire_flag</th>\n",
       "      <td>1301.0</td>\n",
       "      <td>0.509608</td>\n",
       "      <td>0.500100</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         count           mean           std          min  \\\n",
       "hadm_id                 1301.0  148959.273636  29192.003474  100053.0000   \n",
       "icustay_id              1301.0  249784.129900  28869.475428  200065.0000   \n",
       "admission_age           1301.0      63.889437     27.018418      20.2686   \n",
       "los_icu                 1301.0      13.518671     14.276263       0.0012   \n",
       "icustay_seq             1301.0       1.280553      0.644860       1.0000   \n",
       "elixhauser_vanwalraven  1301.0      14.716372      7.811941      -7.0000   \n",
       "oasis                   1301.0      37.843966      9.912514       6.0000   \n",
       "ninety_expire_flag      1301.0       0.509608      0.500100       0.0000   \n",
       "\n",
       "                                25%          50%          75%          max  \n",
       "hadm_id                 123404.0000  148860.0000  174824.0000  199919.0000  \n",
       "icustay_id              224945.0000  250300.0000  274326.0000  299994.0000  \n",
       "admission_age               51.9982      62.4700      73.3998     302.2868  \n",
       "los_icu                      3.9319       9.0294      17.8257     153.9280  \n",
       "icustay_seq                  1.0000       1.0000       1.0000       6.0000  \n",
       "elixhauser_vanwalraven       9.0000      15.0000      20.0000      40.0000  \n",
       "oasis                       31.0000      38.0000      45.0000      66.0000  \n",
       "ninety_expire_flag           0.0000       1.0000       1.0000       1.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icu_cohort.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Sequence Feature Extraction Functions\n",
    "Functions to extract and form __single sample tensor__. We begin by writing two functions: one for extracting the vital signs and another for laboratory data. Because of differences in sampling frequencies, we will extract these two feature sequences separetly, and then we will merge them when generating a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vitals(icustay_id, con, query_schema):\n",
    "    '''\n",
    "    Function arguments:\n",
    "    icustay_id - Numeric ID corresponding to specific ICU stay\n",
    "    con - SQL connection to MIMIC-III database\n",
    "    query_schema: string - part of query to tell where to search\n",
    "    ref_time - if given, used as the reference time for events; \n",
    "                otherwise use earliest time in data.\n",
    "    Returns:\n",
    "    vitals - DataFrame with patients vitals ordered by time\n",
    "    '''\n",
    "    \n",
    "    # perform SQL pull\n",
    "    query = query_schema + '''\n",
    "    SELECT itemid, charttime, icustay_id, valuenum\n",
    "    FROM vitals\n",
    "    WHERE icustay_id = {}\n",
    "    ORDER BY charttime;\n",
    "    '''.format(icustay_id)\n",
    "    vitals = pd.read_sql_query(query, con)\n",
    "    \n",
    "    vitals_map = {211 : 'HR', 220045: 'HR', 51: 'SBP', 442 : 'SBP',\n",
    "                  455 : 'SBP', 6701: 'SBP', 220179 : 'SBP', \n",
    "                  220050: 'SBP', 8368 : 'DBP', 8440 : 'DBP',\n",
    "                  8441 : 'DBP', 8555 : 'DBP', 220180 : 'DBP',\n",
    "                  220051 : 'DBP', 456 : 'MAP', 52 : 'MAP', \n",
    "                  6702 : 'MAP', 443 : 'MAP', 220052 : 'MAP',\n",
    "                  220181 : 'MAP', 225312 : 'MAP', 618 : 'RR',\n",
    "                  615 : 'RR', 220210 : 'RR', 224690 : 'RR',\n",
    "                  646 : 'spO2', 220277 : 'spO2', 223762 : 'tempC',\n",
    "                  676 : 'tempC', 223761 : 'tempF', 678 : 'tempF'}\n",
    "    vitals['vital_type'] = vitals['itemid'].map(vitals_map)\n",
    "    del vitals['itemid']\n",
    "    \n",
    "    return vitals\n",
    "\n",
    "def get_labs(icustay_id, con, query_schema):\n",
    "    '''\n",
    "    Function arguments:\n",
    "    icustay_id - Numeric ID corresponding to specific ICU stay\n",
    "    con - SQL connection to MIMIC-III database\n",
    "    query_schema: string - part of query to tell where to search\n",
    "    ref_time - if given, used as the reference time for events; \n",
    "                otherwise use earliest time in data.\n",
    "    Returns:\n",
    "    labs - DataFrame with patients labs ordered by time\n",
    "    '''\n",
    "    \n",
    "    # perform SQL pull\n",
    "    query = query_schema + '''\n",
    "    SELECT label, charttime, icustay_id, valuenum\n",
    "    FROM lab_item_timeseries\n",
    "    WHERE icustay_id = {}\n",
    "    ORDER BY charttime;\n",
    "    '''.format(icustay_id)\n",
    "    labs = pd.read_sql_query(query, con)\n",
    "    \n",
    "    return labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then want to reshape and resample the vitals into 60 minute intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_vitals(vitals):\n",
    "    '''\n",
    "    Function arguments:\n",
    "    vitals - DataFrame with patients vitals ordered by time\n",
    "    \n",
    "    Returns:\n",
    "    vitals - DataFrame with patients vitals ordered by time, \n",
    "             resampled down to 60 minutes\n",
    "    '''\n",
    "    if (vitals.empty == False):\n",
    "        try:\n",
    "            vitals = vitals.pivot_table(index = 'charttime', \n",
    "                                        columns = 'vital_type', \n",
    "                                        values = 'valuenum', \n",
    "                                        aggfunc = 'mean')\n",
    "            vitals = vitals.resample('60min').mean().reset_index().ffill()\n",
    "        except:\n",
    "            return vitals\n",
    "    \n",
    "    return vitals\n",
    "\n",
    "def resample_labs(labs):\n",
    "    '''\n",
    "    Function arguments:\n",
    "    labs - DataFrame with patient labs ordered by time\n",
    "    \n",
    "    Returns:\n",
    "    labs - DataFrame with patient labs ordered by time, \n",
    "             resampled down to 60 minutes\n",
    "    '''\n",
    "    if (labs.empty == False):\n",
    "        try:\n",
    "            # should explore why some indices are repeated; \n",
    "            # eric: maybe because multiple concepts occurring same time (two MAP reads)\n",
    "            labs = labs.pivot_table(index = 'charttime', columns = 'label', values = 'valuenum', aggfunc = 'mean')\n",
    "            labs = labs.resample('60min').mean().reset_index().ffill()\n",
    "        except:\n",
    "            return labs\n",
    "    \n",
    "    return labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to convert these data into a tensor that can later be stacked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_sequence_feature_tensor(vitals, labs, ref_time, cutoff = 24):\n",
    "    '''\n",
    "    Function arguments:\n",
    "    vitals - DataFrame with patient vitals\n",
    "    labs - DataFrame with patient labs\n",
    "    ref_time - Reference time to take times relative to\n",
    "    \n",
    "    Returns:\n",
    "    labs_tensor - Numpy array, 3D tensor, corresponding to\n",
    "                    one sample, feature x time tensor\n",
    "    '''\n",
    "    \n",
    "    features = vitals.merge(labs, on = 'charttime', how = 'left').ffill()\n",
    "    \n",
    "    # todo: write a func to clean up temp and then add temp here\n",
    "    # todo: also clean up this ugly line if possible\n",
    "    \n",
    "    try:\n",
    "        t = np.array(np.array(ref_time) - np.array(features.charttime), dtype = 'timedelta64[h]').astype(float)\n",
    "    except:\n",
    "        return np.zeros([1, 26, 1])\n",
    "    \n",
    "    \n",
    "    # vitals\n",
    "    if ('HR' in features.columns):\n",
    "        HR = np.array(features.HR)\n",
    "    else:\n",
    "        HR = np.ones(len(t))*np.nan\n",
    "    if ('RR' in features.columns):\n",
    "        RR = np.array(features.RR)\n",
    "    else:\n",
    "        RR = np.ones(len(t))*np.nan\n",
    "    if ('spO2' in features.columns):\n",
    "        spO2 = np.array(features.spO2)\n",
    "    else:\n",
    "        spO2 = np.ones(len(t))*np.nan\n",
    "    if ('MAP' in features.columns):\n",
    "        MAP = np.array(features.MAP)\n",
    "    else:\n",
    "        MAP = np.ones(len(t))*np.nan\n",
    "    if ('SBP' in features.columns):\n",
    "        SBP = np.array(features.SBP)\n",
    "    else:\n",
    "        SBP = np.ones(len(t))*np.nan\n",
    "    if ('DBP' in features.columns):\n",
    "        DBP = np.array(features.DBP)\n",
    "    else:\n",
    "        DBP = np.ones(len(t))*np.nan\n",
    "        \n",
    "    # labs\n",
    "    if ('BICARBONATE' in features.columns):\n",
    "        bicarb = np.array(features.BICARBONATE)\n",
    "    else:\n",
    "        bicarb = np.ones(len(t))*np.nan\n",
    "    if ('CREATININE' in features.columns):\n",
    "        creatinine = np.array(features.CREATININE)\n",
    "    else:\n",
    "        creatinine = np.ones(len(t))*np.nan\n",
    "    if ('CHLORIDE' in features.columns):\n",
    "        chloride = np.array(features.CHLORIDE)\n",
    "    else:\n",
    "        chloride = np.ones(len(t))*np.nan\n",
    "    if ('GLUCOSE' in features.columns):\n",
    "        glucose = np.array(features.GLUCOSE)\n",
    "    else:\n",
    "        glucose = np.ones(len(t))*np.nan\n",
    "    if ('HEMATOCRIT' in features.columns):\n",
    "        hct = np.array(features.HEMATOCRIT)\n",
    "    else:\n",
    "        hct = np.ones(len(t))*np.nan\n",
    "    if ('HEMOGLOBIN' in features.columns):\n",
    "        hgb = np.array(features.HEMOGLOBIN)\n",
    "    else:\n",
    "        hgb = np.ones(len(t))*np.nan\n",
    "    if ('PLATELET' in features.columns):\n",
    "        platelet = np.array(features.PLATELET)\n",
    "    else:\n",
    "        platelet = np.ones(len(t))*np.nan\n",
    "    if ('POTASSIUM' in features.columns):\n",
    "        potassium = np.array(features.POTASSIUM)\n",
    "    else:\n",
    "        potassium = np.ones(len(t))*np.nan\n",
    "    if ('SODIUM' in features.columns):\n",
    "        sodium = np.array(features.SODIUM)\n",
    "    else:\n",
    "        sodium = np.ones(len(t))*np.nan\n",
    "    if ('BUN' in features.columns):\n",
    "        bun = np.array(features.BUN)\n",
    "    else:\n",
    "        bun = np.ones(len(t))*np.nan\n",
    "    if ('WBC' in features.columns):\n",
    "        wbc = np.array(features.WBC)\n",
    "    else:\n",
    "        wbc = np.ones(len(t))*np.nan\n",
    "    \n",
    "    feature_tensor = np.array([[t, HR, RR, spO2, MAP, SBP, DBP, bicarb, creatinine,\\\n",
    "                                chloride, glucose, hct, hgb, platelet,\\\n",
    "                                potassium, sodium, bun, wbc]])\n",
    "    return feature_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Format Tensors for RNN\n",
    "_Considerations:_ Because everyone has a different number of recordings we have to decide how we will handle varying sequence length. How this is handled is crucial because it informs if we'll add padding, where we should cut off recordings, and etc.\n",
    "\n",
    "We'll begin by defining a function to truncuate at a specific time cutoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_tensor(features, trunc_time = 24):\n",
    "    '''\n",
    "    Function arguments:\n",
    "    vitals - DataFrame with patients vitals\n",
    "    trunc_time - Time cutoff to truncate recordings at\n",
    "    \n",
    "    Returns:\n",
    "    vitals - Numpy array, 3D tensor, corresponding to\n",
    "             one sample, feature x time tensor truncated\n",
    "             at truncation time given by user\n",
    "    '''\n",
    "    \n",
    "    keep = features[0, 0, :] <= trunc_time\n",
    "    return features[:, :, keep]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then define a function for adding in the missing rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_missing_steps(features, missing_indicator = np.nan):\n",
    "    '''\n",
    "    Function arguments:\n",
    "    features - DataFrame with patients features\n",
    "    \n",
    "    Returns:\n",
    "    features - Numpy array, 3D tensor, corresponding to\n",
    "             one sample, feature x time tensor with\n",
    "             times missing between t_min and t_max\n",
    "             filled in with np.nan\n",
    "    '''\n",
    "    \n",
    "    features_tn = np.copy(features)\n",
    "    try:\n",
    "        steps_expected = np.max(features_tn[0, 0, :]).astype(int) + 1\n",
    "    except:\n",
    "        return features\n",
    "    \n",
    "    expected_range = np.array(list(reversed(range(steps_expected))))\n",
    "    missing_steps = [x for x in expected_range if not x in features_tn[0, 0, :]]\n",
    "    \n",
    "    if not missing_steps:\n",
    "        return features\n",
    "    \n",
    "    for i, step in enumerate(missing_steps):\n",
    "        index = np.where(expected_range == step)[0] \n",
    "        empty = np.ones((1, features.shape[1], 1))*missing_indicator\n",
    "        empty[0, 0, 0] = step\n",
    "        if (index >= expected_range[0]):\n",
    "            features_tn = np.append(features_tn, empty, 2)\n",
    "        else:\n",
    "            features_tn = np.insert(features_tn, index, empty, 2)\n",
    "    \n",
    "    return features_tn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need a function to pad the tensor with 0s for events which have not yet occurred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_tensor(features, steps_expected = 24):\n",
    "    '''\n",
    "    Function arguents:\n",
    "    features - a (sorted) Numpy array, 3D tensor, corresponding to\n",
    "             one sample, feature x time tensor\n",
    "    '''\n",
    "\n",
    "    try:\n",
    "        pad_size = steps_expected - np.max(features[0, 0, :])\n",
    "    except:\n",
    "        return features\n",
    "    \n",
    "    if (pad_size <= 0):\n",
    "        return features\n",
    "    else:\n",
    "        features_tn = np.copy(features)\n",
    "        for i in range(pad_size.astype(int)):\n",
    "            features_tn = np.insert(features_tn, 0, 0, 2)\n",
    "            \n",
    "    return features_tn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we wrap all of these functions in one function for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sequence_features(icustay_id, con, query_schema, ref_time, trunc_time = 24):\n",
    "    '''\n",
    "    Function arguments:\n",
    "    icustay_id - id of the stay of interest\n",
    "    con - SQL connection to use\n",
    "    query_schema - MIMIC-III db schema\n",
    "    ref_time - time to take charttimes relative to\n",
    "    max_time - t\n",
    "    \n",
    "    Returns:\n",
    "    feature_tensor - Numpy array, 3D tensor, corresponding to\n",
    "             one sample, feature x time tensor truncated,\n",
    "             cleaned, and padded\n",
    "    '''\n",
    "    \n",
    "    # initial pull\n",
    "    vitals_df = get_vitals(icustay_id, con, query_schema)\n",
    "    labs_df = get_labs(icustay_id, con, query_schema)\n",
    "  \n",
    "    # check if pull is empty\n",
    "    if 'charttime' not in vitals_df.columns or vitals_df.charttime.size == 0:\n",
    "        return np.nan\n",
    "    if 'charttime' not in labs_df.columns or labs_df.charttime.size == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    # process DataFrames into a tensor\n",
    "    vitals_df = resample_vitals(vitals_df)\n",
    "    labs_df = resample_labs(labs_df)\n",
    "    \n",
    "    feature_tensor = gen_sequence_feature_tensor(vitals_df, labs_df, ref_time)\n",
    "    feature_tensor = trunc_tensor(feature_tensor, trunc_time)\n",
    "    feature_tensor = add_missing_steps(feature_tensor)\n",
    "    feature_tensor = pad_tensor(feature_tensor)\n",
    "    \n",
    "    return feature_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Cohort-wide Sequence Extraction\n",
    "\n",
    "We now extract a sequence features tensor for each patient in the cohort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohort_ids = icu_cohort.icustay_id\n",
    "\n",
    "feature_dict = {}\n",
    "\n",
    "for current_id in cohort_ids:\n",
    "    current_features = extract_sequence_features(current_id, con, query_schema, icu_cohort.outtime[icu_cohort.icustay_id == current_id], 24)\n",
    "    if current_features is not np.nan and current_features.shape == (1, 18, 25):\n",
    "        feature_dict[current_id] = current_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ICU stays that resulted in a feature tensor returning `np.nan` or with size differing from `(1, 26, 25)` after processing were not in the results, and should be excluded from the cohort. These episodes should be explored further, but there are only ~400 suggesting the issue is not with the code and that these are edge cases. Quick perusal suggests theses are epsiodes in which there were no recordings in the first 24 hours of the stay. While this must be confirmed for all cases, if it is true these patients would be excluded anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = list(set(cohort_ids) - set(feature_dict.keys()))\n",
    "icu_cohort = icu_cohort[icu_cohort.icustay_id.isin(missing) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then stack the resulting tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_sequence = np.vstack(feature_dict.values())[:, 1:26, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a check, we compare the number of samples in each frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_sequence.shape[0] == icu_cohort.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Static Feature Tensor Formatting\n",
    "\n",
    "We now set up vectors for the non-sequence input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Gender:__ binarized (only M or F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F' 'M']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1284,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to vector (label encode)\n",
    "map_gender, f_gender = np.unique(icu_cohort.gender, return_inverse=True)\n",
    "print(map_gender)\n",
    "f_gender.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Admission age:__ continuous variable mapped piecewise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_admission_age = np.copy(icu_cohort.admission_age)\n",
    "f_admission_age[(f_admission_age > 89.5)] = 91.4\n",
    "map_admission_age = np.copy(f_admission_age) # for symmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Ethnicity:__ one hot encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "f_ethnicity = le.fit_transform(icu_cohort.ethnicity)\n",
    "map_ethnicity = le.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LoS in ICU:__ continuous variable\n",
    "\n",
    "*Setting all nans to the minimum value for now , need to figure out why they exist at all*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_los_icu = np.copy(icu_cohort.los_icu)\n",
    "f_los_icu[np.isnan(icu_cohort.los_icu)] = np.min(icu_cohort.los_icu)\n",
    "map_los_icu = np.copy(f_los_icu) # for symmetry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Oasis and Elixhauser:__ Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_oasis = icu_cohort.oasis\n",
    "map_oasis = np.copy(f_oasis)\n",
    "f_elixhauser_vanwalraven = icu_cohort.elixhauser_vanwalraven\n",
    "map_elixhauser_vanwalraven = np.copy(f_elixhauser_vanwalraven)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then save these to a tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_static = np.array([f_gender,\n",
    "     f_admission_age,\n",
    "     f_ethnicity,\n",
    "     f_los_icu,\n",
    "     f_oasis,\n",
    "     f_elixhauser_vanwalraven]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Save Tensors\n",
    "\n",
    "All numpy files saved to `./data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = './'\n",
    "import os\n",
    "# Save static features\n",
    "np.save(data_dir + os.path.sep + 'features_sequence.npy', features_sequence)\n",
    "# Save static features\n",
    "np.save(data_dir + os.path.sep + 'features_static.npy', features_static)\n",
    "# Save Label\n",
    "label = icu_cohort.ninety_expire_flag\n",
    "np.save(data_dir + os.path.sep + 'labels.npy', label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
